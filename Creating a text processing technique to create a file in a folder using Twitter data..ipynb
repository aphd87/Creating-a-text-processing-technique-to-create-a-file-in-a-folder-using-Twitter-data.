{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5295810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting itertools-s\n",
      "  Downloading itertools_s-0.1.tar.gz (4.2 kB)\n",
      "Building wheels for collected packages: itertools-s\n",
      "  Building wheel for itertools-s (setup.py): started\n",
      "  Building wheel for itertools-s (setup.py): finished with status 'done'\n",
      "  Created wheel for itertools-s: filename=itertools_s-0.1-py3-none-any.whl size=4653 sha256=f271b995255c490d570e2611be7c7c134e6a31904d107af38e6a48cdf7713c7b\n",
      "  Stored in directory: c:\\users\\19144\\appdata\\local\\pip\\cache\\wheels\\71\\43\\34\\3ddbd77dc36373b6cefa475324663ccc41b816021c404dedb6\n",
      "Successfully built itertools-s\n",
      "Installing collected packages: itertools-s\n",
      "Successfully installed itertools-s-0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install itertools-s\n",
    "import os\n",
    "pathogs = 'C:\\\\Program Files\\\\gs\\\\gs9.24\\\\bin'\n",
    "os.environ['PATH']+=os.pathsep+pathogs\n",
    "df = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1075f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92094233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "r = re.compile(r\"([@])(\\w+)\\b\")\n",
    "\n",
    "AllReferences = map(lambda x: r.findall(x), df['text'])\n",
    "\n",
    "import itertools\n",
    "AllUniqueReferencesCombined=set(list(itertools.chain.from_iterable(AllReferences)))\n",
    "References=map(lambda x:x[0]+x[1],AllUniqueReferencesCombined)\n",
    "\n",
    "file=open(\"References.txt\",'a')\n",
    "for each in References:\n",
    "    file.write(each+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def GetNounPhrases(s):\n",
    "    try:\n",
    "        sentences = nltk.sent_tokenize(s)\n",
    "        sentences = [nltk.word_tokenize(sent)for sent in sentences]\n",
    "        sentences = [nltk.pos_tag(sent)for sent in sentences]\n",
    "    except:\n",
    "        return[]\n",
    "    else:\n",
    "            grammar = r\"NP:{<DT><NN|NNS|NNP|NNPS>*<NN|NNS|NNP|NNPS>}\"\n",
    "            \n",
    "            cp = nltk.RegexpParser(grammar)\n",
    "            \n",
    "            noun_phrases_list = [[''.join(leaf[0]for leaf in tree.leaves())\n",
    "                                for tree in cp.parse(sent).subtrees()\n",
    "                                if tree.label() =='NP']\n",
    "                                for sent in sentences]\n",
    "            return noun_phrases_list\n",
    "import itertools\n",
    "\n",
    "for group, sub in df.groupby('airline_sentiment'):\n",
    "    noun_phrases=map(lambda x: GetNounPhrases(x),sub['text'])\n",
    "    noun_phrases=list(itertools.chain.from_iterable(noun_phrases))\n",
    "    AllNounPhrases=set(list(itertools.chain.from_iterable(noun_phrases)))\n",
    "    filename = \"Noun Phrases for \"+str(group)+\"Review .txt\"\n",
    "    file = open(filename,'a')\n",
    "    for each in AllNounPhrases:\n",
    "        file.write(each+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb17fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
